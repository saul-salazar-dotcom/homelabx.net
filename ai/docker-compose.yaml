name: ai

networks:
  proxy:
    external: true

services:
  chatgpt:
    image: ghcr.io/ivanfioravanti/chatbot-ollama:main
    ports:
      - 3000:3000
    environment:
      - DEFAULT_MODEL=llama2
      - OLLAMA_HOST=http://ollama:11434
    networks:
      - default
      - proxy
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.${COMPOSE_PROJECT_NAME}.rule=HostRegexp(`ai.{ip:.*}.traefik.me`)"
      - "traefik.http.routers.${COMPOSE_PROJECT_NAME}.entrypoints=https"
      - "traefik.http.routers.${COMPOSE_PROJECT_NAME}.tls=true"
      - "traefik.http.services.${COMPOSE_PROJECT_NAME}.loadbalancer.server.port=3000"

  ollama:
    image: ollama/ollama
    volumes:
      - ./ollama/models:/ollama/models
    environment:
      - OLLAMA_MODELS=/ollama/models
